#!/bin/bash -l
#SBATCH -N __nodes__
#SBATCH -t __walltime__
#SBATCH -o __job_name__.o%j

# Define environment variables needed
EXE_PATH="__executable_path__"
SCRIPTS_DIR="__scripts_dir__"
WORK_DIR="__working_dir__"
RESULTS_DIR="__results_dir__"
HARNESS_ID="__harness_id__"
BUILD_DIR="__build_dir__"

source ${BUILD_DIR}/Common_Scripts/env.sh

module -t list

echo "Printing test directory environment variables:"
env | fgrep RGT_APP_SOURCE_
env | fgrep RGT_TEST_
echo

# Ensure we are in the starting directory
cd $SCRIPTS_DIR

# Make the working scratch space directory.
if [ ! -e $WORK_DIR ]
then
    mkdir -p $WORK_DIR
fi

# Change directory to the working directory.
cd $WORK_DIR

env &> job.environ
scontrol show hostnames > job.nodes

# Run the executable.
log_binary_execution_time.py --scriptsdir $SCRIPTS_DIR --uniqueid $HARNESS_ID --mode start

for src_file in `find ${BUILD_DIR}/${EXE_PATH} -name "*.c"`; do
    exe_path=`echo $src_file | sed -e "s|/| |g"`
    IFS=' ' read -ra exe_arr <<< $exe_path
    exe_short_name=${exe_arr[${#exe_arr[@]}-1]}
    short_exe=`echo ${exe_short_name} | cut -d. -f1`

    ranks_per_node=__processes_per_node__

    # RGT_TASKS_PER_NODE set by env.sh, OSU_USE_GPU is set by the rgt_test_input.ini, sets 1 rank per GPU
    if [ ! -z ${RGT_TASKS_PER_NODE} ] && [ ${OSU_USE_GPU:-0} == 1 ]; then
        ranks_per_node=${RGT_TASKS_PER_NODE}
    fi

    # SLURM is bad at math, so let's do the math here:
    nranks=`expr ${ranks_per_node} \* ${SLURM_NNODES}`

    # Binds GPUs - CPU-only tests will ignore them
    CMD="srun --ntasks-per-node=${ranks_per_node} -n ${nranks} -N ${SLURM_NNODES} -m block,nopack --gpus-per-node=${RGT_TASKS_PER_NODE} --gpu-bind=closest $BUILD_DIR/get_local_rank $BUILD_DIR/$EXE_PATH/${short_exe} $EXECUTABLE_FLAGS"
    echo "$CMD &> ${short_exe}.out"
    $CMD &> ${short_exe}.out
done

log_binary_execution_time.py --scriptsdir $SCRIPTS_DIR --uniqueid $HARNESS_ID --mode final

# Ensure we return to the starting directory.
cd $SCRIPTS_DIR

# Copy the output and results back to the $RESULTS_DIR
cp -rf $WORK_DIR/* $RESULTS_DIR 

# Check the final results.
check_executable_driver.py -p $RESULTS_DIR -i $HARNESS_ID

# Resubmit if needed
case __resubmit__ in
    0) 
       echo "No resubmit";;
    1) 
       test_harness_driver.py -r;;
esac 

